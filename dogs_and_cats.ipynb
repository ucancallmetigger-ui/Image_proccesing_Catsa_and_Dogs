{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMGdVK3F9jvCYuQI8sVQRsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucancallmetigger-ui/Image_proccesing_Catsa_and_Dogs/blob/main/dogs_and_cats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dPAuuSPBlBoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets torchvision torch --quiet\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "dataset = load_dataset(\"microsoft/cats_vs_dogs\")['train']\n",
        "\n",
        "class HFImageDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, transform=None):\n",
        "        self.hf_dataset = hf_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hf_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.hf_dataset[idx]\n",
        "        image = item['image'].convert(\"RGB\")\n",
        "        label = item['labels']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "full_dataset = HFImageDataset(dataset, transform=transform_train)\n",
        "\n",
        "cat_indices = [i for i in range(len(dataset)) if dataset[i]['labels'] == 0]\n",
        "dog_indices = [i for i in range(len(dataset)) if dataset[i]['labels'] == 1]\n",
        "\n",
        "random.seed(42)\n",
        "train_cat = random.sample(cat_indices, 500)\n",
        "train_dog = random.sample(dog_indices, 500)\n",
        "train_indices = train_cat + train_dog\n",
        "random.shuffle(train_indices)\n",
        "\n",
        "remaining_cat = list(set(cat_indices) - set(train_cat))\n",
        "remaining_dog = list(set(dog_indices) - set(train_dog))\n",
        "test_cat = random.sample(remaining_cat, 500)\n",
        "test_dog = random.sample(remaining_dog, 500)\n",
        "test_indices = test_cat + test_dog\n",
        "random.shuffle(test_indices)\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
        "\n",
        "test_dataset_raw = HFImageDataset(dataset, transform=transform_test)\n",
        "test_dataset = torch.utils.data.Subset(test_dataset_raw, test_indices)\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "for epoch in range(25):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.float().unsqueeze(1).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    scheduler.step()\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs, labels = inputs.to(device), labels.float().unsqueeze(1).to(device)\n",
        "        outputs = model(inputs)\n",
        "        predicted = torch.sigmoid(outputs) > 0.5\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"دقت نهایی روی ۱۰۰۰ تصویر تست: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "_1_xkG7ZwwMc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}